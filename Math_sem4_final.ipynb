{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "load dataset from movielens\n"
      ],
      "metadata": {
        "id": "3GPGK2HJaQ8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip -n ml-100k.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wINWRLgpUOVE",
        "outputId": "0e6a69da-47c7-4db3-ca53-f48ab78f83ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-11 18:26:20--  https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  14.3MB/s    in 0.3s    \n",
            "\n",
            "2025-05-11 18:26:21 (14.3 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "normal SGD\n"
      ],
      "metadata": {
        "id": "KY4dwjWcadDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "ratings_df = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "\n",
        "# Adjust user and movie IDs to start from 0\n",
        "ratings_df['user_id'] -= 1\n",
        "ratings_df['movie_id'] -= 1\n",
        "\n",
        "ratings_list = list(ratings_df[['user_id', 'movie_id', 'rating']].itertuples(index=False, name=None))\n",
        "\n",
        "n_users = ratings_df['user_id'].nunique()\n",
        "n_movies = ratings_df['movie_id'].nunique()\n",
        "\n",
        "train_ratings, test_ratings = train_test_split(ratings_list, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Data Loaded: {len(ratings_list)} ratings, {len(train_ratings)} train, {len(test_ratings)} test.\")\n",
        "\n",
        "def init_model(n_users, n_movies, n_factors=20):\n",
        "    np.random.seed(42)\n",
        "    U = np.random.normal(0, 0.1, (n_users, n_factors)) # Initialize user feature matrix U (n_users × n_factors) with small random numbers\n",
        "    V = np.random.normal(0, 0.1, (n_movies, n_factors)) # Initialize item feature matrix V (n_movies × n_factors) with small random numbers\n",
        "    user_bias = np.zeros(n_users)\n",
        "    item_bias = np.zeros(n_movies)\n",
        "    global_mean = 0\n",
        "    return U, V, user_bias, item_bias, global_mean\n",
        "\n",
        "def train_model_sgd(U, V, user_bias, item_bias, global_mean, train_data, n_factors=20, lr=0.01, reg=0.1, epochs=40):\n",
        "    global_mean = np.mean([r for _, _, r in train_data])\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        np.random.shuffle(train_data)\n",
        "        total_loss = 0\n",
        "\n",
        "        for user, movie, rating in train_data:\n",
        "            pred = predict(U, V, user_bias, item_bias, global_mean, user, movie)\n",
        "            err = rating - pred\n",
        "            total_loss += err ** 2\n",
        "\n",
        "            # Update biases\n",
        "            user_bias[user] += lr * (err - reg * user_bias[user])\n",
        "            item_bias[movie] += lr * (err - reg * item_bias[movie])\n",
        "\n",
        "            # Update latent features\n",
        "            U_old = U[user].copy()\n",
        "            V_old = V[movie].copy()\n",
        "\n",
        "            U[user] += lr * (err * V_old - reg * U_old)\n",
        "            V[movie] += lr * (err * U_old - reg * V_old)\n",
        "\n",
        "        mse = total_loss / len(train_data)\n",
        "        print(f\"Epoch {ep+1}/{epochs} - MSE: {mse:.4f}\")\n",
        "\n",
        "    return U, V, user_bias, item_bias, global_mean\n",
        "\n",
        "def predict(U, V, user_bias, item_bias, global_mean, user, movie):\n",
        "    dot = np.dot(U[user], V[movie])\n",
        "    # Add biases and global mean\n",
        "    return global_mean + user_bias[user] + item_bias[movie] + dot\n",
        "\n",
        "U, V, user_bias, item_bias, global_mean = init_model(n_users, n_movies, n_factors=75)\n",
        "U, V, user_bias, item_bias, global_mean = train_model_sgd(U, V, user_bias, item_bias, global_mean,\n",
        "                                                      train_ratings, n_factors=75, lr=0.01, reg=0.1, epochs=75)\n",
        "\n",
        "predictions = []\n",
        "truths = []\n",
        "\n",
        "for user, movie, real_rating in test_ratings:\n",
        "    pred_rating = predict(U, V, user_bias, item_bias, global_mean, user, movie)\n",
        "    predictions.append(pred_rating)\n",
        "    truths.append(real_rating)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(truths, predictions))\n",
        "print(f\"\\n✅ Test RMSE: {rmse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B48X4ohsGHpp",
        "outputId": "53901b03-44ec-41df-eabe-d42b95a5d76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded: 100000 ratings, 80000 train, 20000 test.\n",
            "Epoch 1/75 - MSE: 1.0491\n",
            "Epoch 2/75 - MSE: 0.9120\n",
            "Epoch 3/75 - MSE: 0.8713\n",
            "Epoch 4/75 - MSE: 0.8497\n",
            "Epoch 5/75 - MSE: 0.8355\n",
            "Epoch 6/75 - MSE: 0.8244\n",
            "Epoch 7/75 - MSE: 0.8153\n",
            "Epoch 8/75 - MSE: 0.8073\n",
            "Epoch 9/75 - MSE: 0.7990\n",
            "Epoch 10/75 - MSE: 0.7906\n",
            "Epoch 11/75 - MSE: 0.7821\n",
            "Epoch 12/75 - MSE: 0.7721\n",
            "Epoch 13/75 - MSE: 0.7622\n",
            "Epoch 14/75 - MSE: 0.7513\n",
            "Epoch 15/75 - MSE: 0.7405\n",
            "Epoch 16/75 - MSE: 0.7288\n",
            "Epoch 17/75 - MSE: 0.7174\n",
            "Epoch 18/75 - MSE: 0.7062\n",
            "Epoch 19/75 - MSE: 0.6951\n",
            "Epoch 20/75 - MSE: 0.6838\n",
            "Epoch 21/75 - MSE: 0.6727\n",
            "Epoch 22/75 - MSE: 0.6622\n",
            "Epoch 23/75 - MSE: 0.6516\n",
            "Epoch 24/75 - MSE: 0.6412\n",
            "Epoch 25/75 - MSE: 0.6311\n",
            "Epoch 26/75 - MSE: 0.6212\n",
            "Epoch 27/75 - MSE: 0.6114\n",
            "Epoch 28/75 - MSE: 0.6020\n",
            "Epoch 29/75 - MSE: 0.5932\n",
            "Epoch 30/75 - MSE: 0.5845\n",
            "Epoch 31/75 - MSE: 0.5760\n",
            "Epoch 32/75 - MSE: 0.5683\n",
            "Epoch 33/75 - MSE: 0.5605\n",
            "Epoch 34/75 - MSE: 0.5530\n",
            "Epoch 35/75 - MSE: 0.5461\n",
            "Epoch 36/75 - MSE: 0.5394\n",
            "Epoch 37/75 - MSE: 0.5333\n",
            "Epoch 38/75 - MSE: 0.5267\n",
            "Epoch 39/75 - MSE: 0.5209\n",
            "Epoch 40/75 - MSE: 0.5160\n",
            "Epoch 41/75 - MSE: 0.5108\n",
            "Epoch 42/75 - MSE: 0.5059\n",
            "Epoch 43/75 - MSE: 0.5007\n",
            "Epoch 44/75 - MSE: 0.4964\n",
            "Epoch 45/75 - MSE: 0.4924\n",
            "Epoch 46/75 - MSE: 0.4883\n",
            "Epoch 47/75 - MSE: 0.4846\n",
            "Epoch 48/75 - MSE: 0.4805\n",
            "Epoch 49/75 - MSE: 0.4769\n",
            "Epoch 50/75 - MSE: 0.4735\n",
            "Epoch 51/75 - MSE: 0.4707\n",
            "Epoch 52/75 - MSE: 0.4675\n",
            "Epoch 53/75 - MSE: 0.4645\n",
            "Epoch 54/75 - MSE: 0.4618\n",
            "Epoch 55/75 - MSE: 0.4590\n",
            "Epoch 56/75 - MSE: 0.4565\n",
            "Epoch 57/75 - MSE: 0.4543\n",
            "Epoch 58/75 - MSE: 0.4519\n",
            "Epoch 59/75 - MSE: 0.4500\n",
            "Epoch 60/75 - MSE: 0.4478\n",
            "Epoch 61/75 - MSE: 0.4455\n",
            "Epoch 62/75 - MSE: 0.4436\n",
            "Epoch 63/75 - MSE: 0.4416\n",
            "Epoch 64/75 - MSE: 0.4401\n",
            "Epoch 65/75 - MSE: 0.4383\n",
            "Epoch 66/75 - MSE: 0.4367\n",
            "Epoch 67/75 - MSE: 0.4350\n",
            "Epoch 68/75 - MSE: 0.4340\n",
            "Epoch 69/75 - MSE: 0.4324\n",
            "Epoch 70/75 - MSE: 0.4309\n",
            "Epoch 71/75 - MSE: 0.4297\n",
            "Epoch 72/75 - MSE: 0.4281\n",
            "Epoch 73/75 - MSE: 0.4273\n",
            "Epoch 74/75 - MSE: 0.4255\n",
            "Epoch 75/75 - MSE: 0.4246\n",
            "\n",
            "✅ Test RMSE: 0.9107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "kernelized mean SGD"
      ],
      "metadata": {
        "id": "fpW4YtzLagai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "ratings_df = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "ratings_df['user_id'] -= 1\n",
        "ratings_df['movie_id'] -= 1\n",
        "\n",
        "ratings_list = list(ratings_df[['user_id', 'movie_id', 'rating']].itertuples(index=False, name=None))\n",
        "\n",
        "n_users = ratings_df['user_id'].nunique()\n",
        "n_movies = ratings_df['movie_id'].nunique()\n",
        "\n",
        "train_data, test_data = train_test_split(ratings_list, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Data Loaded! {len(ratings_list)} ratings: {len(train_data)} train, {len(test_data)} test.\")\n",
        "\n",
        "def init_model(n_users, n_movies, n_factors=20):\n",
        "    np.random.seed(0)\n",
        "    U = np.random.normal(0, 0.1, (n_users, n_factors))\n",
        "    V = np.random.normal(0, 0.1, (n_movies, n_factors))\n",
        "    user_bias = np.zeros(n_users)\n",
        "    item_bias = np.zeros(n_movies)\n",
        "    global_mean = 0\n",
        "    return U, V, user_bias, item_bias, global_mean\n",
        "\n",
        "def rbf_kernel(x, y, sigma=1.0):\n",
        "    \"\"\"Gaussian (RBF) kernel between x and y.\"\"\"\n",
        "    diff = x - y\n",
        "    return np.exp(-np.dot(diff, diff) / (2 * sigma ** 2))\n",
        "\n",
        "def predict_rbf(U, V, user_bias, item_bias, global_mean, user, movie, sigma=1.0):\n",
        "    kernel_val = rbf_kernel(U[user], V[movie], sigma)\n",
        "    return global_mean + user_bias[user] + item_bias[movie] + kernel_val\n",
        "\n",
        "def train_model_rbf(U, V, user_bias, item_bias, global_mean, train_data,\n",
        "                      n_factors=20, lr=0.005, reg=0.1, epochs=30, sigma=1.0):\n",
        "    global_mean = np.mean([r for _, _, r in train_data])\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        np.random.shuffle(train_data)\n",
        "        total_loss = 0\n",
        "\n",
        "        for user, movie, rating in train_data:\n",
        "            pred = predict_rbf(U, V, user_bias, item_bias, global_mean, user, movie, sigma)\n",
        "            err = rating - pred\n",
        "            total_loss += err ** 2\n",
        "\n",
        "            # Gradients for kernel part\n",
        "            diff = U[user] - V[movie]\n",
        "            grad_kernel = (np.exp(-np.dot(diff, diff) / (2 * sigma ** 2)) * diff) / (sigma ** 2)\n",
        "\n",
        "            # Update biases\n",
        "            user_bias[user] += lr * (err - reg * user_bias[user])\n",
        "            item_bias[movie] += lr * (err - reg * item_bias[movie])\n",
        "\n",
        "            # Update latent features\n",
        "            U[user] += lr * (err * grad_kernel - reg * U[user])\n",
        "            V[movie] -= lr * (err * grad_kernel + reg * V[movie])\n",
        "\n",
        "        mse = total_loss / len(train_data)\n",
        "        print(f\"Epoch {ep+1}/{epochs} - Train MSE: {mse:.4f}\")\n",
        "\n",
        "    return U, V, user_bias, item_bias, global_mean\n",
        "\n",
        "U, V, user_bias, item_bias, global_mean = init_model(n_users, n_movies, n_factors=50)\n",
        "\n",
        "U, V, user_bias, item_bias, global_mean = train_model_rbf(\n",
        "    U, V, user_bias, item_bias, global_mean,\n",
        "    train_data,\n",
        "    n_factors=50, lr=0.01, reg=0.1,\n",
        "    epochs=50, sigma=1.5\n",
        ")\n",
        "\n",
        "predictions = []\n",
        "truths = []\n",
        "\n",
        "for user, movie, real_rating in test_data:\n",
        "    pred_rating = predict_rbf(U, V, user_bias, item_bias, global_mean, user, movie, sigma=1.5)\n",
        "    predictions.append(pred_rating)\n",
        "    truths.append(real_rating)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(truths, predictions))\n",
        "print(f\"\\n✅ Test RMSE (KMSGD): {rmse:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4GiAJ6gZTJ_",
        "outputId": "8da283c6-3d59-454f-af98-39ef4775d60c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded! 100000 ratings: 80000 train, 20000 test.\n",
            "Epoch 1/50 - Train MSE: 1.2464\n",
            "Epoch 2/50 - Train MSE: 0.9893\n",
            "Epoch 3/50 - Train MSE: 0.9393\n",
            "Epoch 4/50 - Train MSE: 0.9141\n",
            "Epoch 5/50 - Train MSE: 0.8995\n",
            "Epoch 6/50 - Train MSE: 0.8902\n",
            "Epoch 7/50 - Train MSE: 0.8828\n",
            "Epoch 8/50 - Train MSE: 0.8783\n",
            "Epoch 9/50 - Train MSE: 0.8743\n",
            "Epoch 10/50 - Train MSE: 0.8715\n",
            "Epoch 11/50 - Train MSE: 0.8695\n",
            "Epoch 12/50 - Train MSE: 0.8674\n",
            "Epoch 13/50 - Train MSE: 0.8657\n",
            "Epoch 14/50 - Train MSE: 0.8646\n",
            "Epoch 15/50 - Train MSE: 0.8630\n",
            "Epoch 16/50 - Train MSE: 0.8624\n",
            "Epoch 17/50 - Train MSE: 0.8611\n",
            "Epoch 18/50 - Train MSE: 0.8608\n",
            "Epoch 19/50 - Train MSE: 0.8601\n",
            "Epoch 20/50 - Train MSE: 0.8594\n",
            "Epoch 21/50 - Train MSE: 0.8589\n",
            "Epoch 22/50 - Train MSE: 0.8580\n",
            "Epoch 23/50 - Train MSE: 0.8581\n",
            "Epoch 24/50 - Train MSE: 0.8575\n",
            "Epoch 25/50 - Train MSE: 0.8566\n",
            "Epoch 26/50 - Train MSE: 0.8567\n",
            "Epoch 27/50 - Train MSE: 0.8565\n",
            "Epoch 28/50 - Train MSE: 0.8561\n",
            "Epoch 29/50 - Train MSE: 0.8558\n",
            "Epoch 30/50 - Train MSE: 0.8556\n",
            "Epoch 31/50 - Train MSE: 0.8556\n",
            "Epoch 32/50 - Train MSE: 0.8549\n",
            "Epoch 33/50 - Train MSE: 0.8548\n",
            "Epoch 34/50 - Train MSE: 0.8547\n",
            "Epoch 35/50 - Train MSE: 0.8543\n",
            "Epoch 36/50 - Train MSE: 0.8542\n",
            "Epoch 37/50 - Train MSE: 0.8541\n",
            "Epoch 38/50 - Train MSE: 0.8538\n",
            "Epoch 39/50 - Train MSE: 0.8538\n",
            "Epoch 40/50 - Train MSE: 0.8539\n",
            "Epoch 41/50 - Train MSE: 0.8534\n",
            "Epoch 42/50 - Train MSE: 0.8530\n",
            "Epoch 43/50 - Train MSE: 0.8534\n",
            "Epoch 44/50 - Train MSE: 0.8527\n",
            "Epoch 45/50 - Train MSE: 0.8533\n",
            "Epoch 46/50 - Train MSE: 0.8528\n",
            "Epoch 47/50 - Train MSE: 0.8527\n",
            "Epoch 48/50 - Train MSE: 0.8527\n",
            "Epoch 49/50 - Train MSE: 0.8526\n",
            "Epoch 50/50 - Train MSE: 0.8523\n",
            "\n",
            "✅ Test RMSE (KMSGD): 0.944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch SGD\n"
      ],
      "metadata": {
        "id": "4XY2zBxlak39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "ratings_df = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "ratings_df['user_id'] -= 1\n",
        "ratings_df['movie_id'] -= 1\n",
        "\n",
        "ratings_list = list(ratings_df[['user_id', 'movie_id', 'rating']].itertuples(index=False, name=None))\n",
        "\n",
        "n_users = ratings_df['user_id'].nunique()\n",
        "n_movies = ratings_df['movie_id'].nunique()\n",
        "\n",
        "train_data, test_data = train_test_split(ratings_list, test_size=0.2, random_state=0)\n",
        "\n",
        "print(f\"Data Loaded! {len(ratings_list)} ratings: {len(train_data)} train, {len(test_data)} test.\")\n",
        "\n",
        "def init_model(n_users, n_movies, n_factors=20):\n",
        "    np.random.seed(0)\n",
        "    U = np.random.normal(0, 0.1, (n_users, n_factors))\n",
        "    V = np.random.normal(0, 0.1, (n_movies, n_factors))\n",
        "    user_bias = np.zeros(n_users)\n",
        "    item_bias = np.zeros(n_movies)\n",
        "    global_mean = 0\n",
        "    return U, V, user_bias, item_bias, global_mean\n",
        "\n",
        "def predict(U, V, user_bias, item_bias, global_mean, user, movie):\n",
        "    dot = np.dot(U[user], V[movie])\n",
        "    return global_mean + user_bias[user] + item_bias[movie] + dot\n",
        "\n",
        "def train_model_batch(U, V, user_bias, item_bias, global_mean, train_data,\n",
        "                          n_factors=20, lr=0.005, reg=0.1, epochs=30, batch_size=32):\n",
        "    global_mean = np.mean([r for _, _, r in train_data])\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        np.random.shuffle(train_data)\n",
        "        total_loss = 0\n",
        "\n",
        "        for i in range(0, len(train_data), batch_size):\n",
        "            batch = train_data[i:i+batch_size]\n",
        "\n",
        "            # Initialize batch gradients\n",
        "            grad_U = np.zeros_like(U)\n",
        "            grad_V = np.zeros_like(V)\n",
        "            grad_user_bias = np.zeros_like(user_bias)\n",
        "            grad_item_bias = np.zeros_like(item_bias)\n",
        "\n",
        "            for user, movie, rating in batch:\n",
        "                pred = predict(U, V, user_bias, item_bias, global_mean, user, movie)\n",
        "                err = rating - pred\n",
        "                total_loss += err ** 2\n",
        "\n",
        "                # Accumulate gradients\n",
        "                grad_U[user] += -(err * V[movie]) + reg * U[user]\n",
        "                grad_V[movie] += -(err * U[user]) + reg * V[movie]\n",
        "                grad_user_bias[user] += -err + reg * user_bias[user]\n",
        "                grad_item_bias[movie] += -err + reg * item_bias[movie]\n",
        "\n",
        "            # Normalize gradients by batch size\n",
        "            grad_U /= batch_size\n",
        "            grad_V /= batch_size\n",
        "            grad_user_bias /= batch_size\n",
        "            grad_item_bias /= batch_size\n",
        "\n",
        "            # Update parameters\n",
        "            U += -lr * grad_U\n",
        "            V += -lr * grad_V\n",
        "            user_bias += -lr * grad_user_bias\n",
        "            item_bias += -lr * grad_item_bias\n",
        "\n",
        "        mse = total_loss / len(train_data)\n",
        "        print(f\"Epoch {ep+1}/{epochs} - Train MSE: {mse:.4f}\")\n",
        "\n",
        "    return U, V, user_bias, item_bias, global_mean\n",
        "\n",
        "\n",
        "U, V, user_bias, item_bias, global_mean = init_model(n_users, n_movies, n_factors=50)\n",
        "\n",
        "U, V, user_bias, item_bias, global_mean = train_model_batch(\n",
        "    U, V, user_bias, item_bias, global_mean,\n",
        "    train_data,\n",
        "    n_factors=50, lr=0.01, reg=0.1,\n",
        "    epochs=50, batch_size=4\n",
        ")\n",
        "\n",
        "predictions = []\n",
        "truths = []\n",
        "\n",
        "for user, movie, real_rating in test_data:\n",
        "    pred_rating = predict(U, V, user_bias, item_bias, global_mean, user, movie)\n",
        "    predictions.append(pred_rating)\n",
        "    truths.append(real_rating)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(truths, predictions))\n",
        "print(f\"\\n✅ Test RMSE (KMSGD): {rmse:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5wHq-M3-BFe",
        "outputId": "9c87786f-be98-4397-8ecc-41958a152245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded! 100000 ratings: 80000 train, 20000 test.\n",
            "Epoch 1/50 - Train MSE: 1.1594\n",
            "Epoch 2/50 - Train MSE: 1.0340\n",
            "Epoch 3/50 - Train MSE: 0.9774\n",
            "Epoch 4/50 - Train MSE: 0.9444\n",
            "Epoch 5/50 - Train MSE: 0.9223\n",
            "Epoch 6/50 - Train MSE: 0.9061\n",
            "Epoch 7/50 - Train MSE: 0.8935\n",
            "Epoch 8/50 - Train MSE: 0.8834\n",
            "Epoch 9/50 - Train MSE: 0.8751\n",
            "Epoch 10/50 - Train MSE: 0.8682\n",
            "Epoch 11/50 - Train MSE: 0.8621\n",
            "Epoch 12/50 - Train MSE: 0.8571\n",
            "Epoch 13/50 - Train MSE: 0.8523\n",
            "Epoch 14/50 - Train MSE: 0.8483\n",
            "Epoch 15/50 - Train MSE: 0.8447\n",
            "Epoch 16/50 - Train MSE: 0.8413\n",
            "Epoch 17/50 - Train MSE: 0.8384\n",
            "Epoch 18/50 - Train MSE: 0.8356\n",
            "Epoch 19/50 - Train MSE: 0.8329\n",
            "Epoch 20/50 - Train MSE: 0.8306\n",
            "Epoch 21/50 - Train MSE: 0.8285\n",
            "Epoch 22/50 - Train MSE: 0.8263\n",
            "Epoch 23/50 - Train MSE: 0.8242\n",
            "Epoch 24/50 - Train MSE: 0.8222\n",
            "Epoch 25/50 - Train MSE: 0.8204\n",
            "Epoch 26/50 - Train MSE: 0.8186\n",
            "Epoch 27/50 - Train MSE: 0.8168\n",
            "Epoch 28/50 - Train MSE: 0.8150\n",
            "Epoch 29/50 - Train MSE: 0.8133\n",
            "Epoch 30/50 - Train MSE: 0.8116\n",
            "Epoch 31/50 - Train MSE: 0.8099\n",
            "Epoch 32/50 - Train MSE: 0.8083\n",
            "Epoch 33/50 - Train MSE: 0.8066\n",
            "Epoch 34/50 - Train MSE: 0.8048\n",
            "Epoch 35/50 - Train MSE: 0.8032\n",
            "Epoch 36/50 - Train MSE: 0.8014\n",
            "Epoch 37/50 - Train MSE: 0.7997\n",
            "Epoch 38/50 - Train MSE: 0.7979\n",
            "Epoch 39/50 - Train MSE: 0.7961\n",
            "Epoch 40/50 - Train MSE: 0.7942\n",
            "Epoch 41/50 - Train MSE: 0.7923\n",
            "Epoch 42/50 - Train MSE: 0.7904\n",
            "Epoch 43/50 - Train MSE: 0.7883\n",
            "Epoch 44/50 - Train MSE: 0.7865\n",
            "Epoch 45/50 - Train MSE: 0.7844\n",
            "Epoch 46/50 - Train MSE: 0.7822\n",
            "Epoch 47/50 - Train MSE: 0.7801\n",
            "Epoch 48/50 - Train MSE: 0.7778\n",
            "Epoch 49/50 - Train MSE: 0.7756\n",
            "Epoch 50/50 - Train MSE: 0.7733\n",
            "\n",
            "✅ Test RMSE (KMSGD): 0.936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch + momentum SGD\n"
      ],
      "metadata": {
        "id": "zPBTrpk-ao5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "ratings_df = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "ratings_df['user_id'] -= 1\n",
        "ratings_df['movie_id'] -= 1\n",
        "\n",
        "ratings_list = list(ratings_df[['user_id', 'movie_id', 'rating']].itertuples(index=False, name=None))\n",
        "\n",
        "n_users = ratings_df['user_id'].nunique()\n",
        "n_movies = ratings_df['movie_id'].nunique()\n",
        "\n",
        "train_data, test_data = train_test_split(ratings_list, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Data Loaded! {len(ratings_list)} ratings: {len(train_data)} train, {len(test_data)} test.\")\n",
        "\n",
        "def init_model(n_users, n_movies, n_factors=20):\n",
        "    np.random.seed(0)\n",
        "    U = np.random.normal(0, 0.1, (n_users, n_factors))\n",
        "    V = np.random.normal(0, 0.1, (n_movies, n_factors))\n",
        "    user_bias = np.zeros(n_users)\n",
        "    item_bias = np.zeros(n_movies)\n",
        "    global_mean = 0\n",
        "    return U, V, user_bias, item_bias, global_mean\n",
        "\n",
        "def predict(U, V, user_bias, item_bias, global_mean, user, movie):\n",
        "    dot = np.dot(U[user], V[movie])\n",
        "    return global_mean + user_bias[user] + item_bias[movie] + dot\n",
        "\n",
        "def train_model_sgd_batch_momentum(U, V, user_bias, item_bias, global_mean, train_data,\n",
        "                                   n_factors=20, lr=0.005, reg=0.1, epochs=30, batch_size=32,\n",
        "                                   momentum=0.9):\n",
        "    global_mean = np.mean([r for _, _, r in train_data])\n",
        "\n",
        "    # Initialize momentum terms (velocities)\n",
        "    vel_U = np.zeros_like(U)\n",
        "    vel_V = np.zeros_like(V)\n",
        "    vel_user_bias = np.zeros_like(user_bias)\n",
        "    vel_item_bias = np.zeros_like(item_bias)\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        np.random.shuffle(train_data)\n",
        "        total_loss = 0\n",
        "\n",
        "        for i in range(0, len(train_data), batch_size):\n",
        "            batch = train_data[i:i+batch_size]\n",
        "\n",
        "            grad_U = np.zeros_like(U)\n",
        "            grad_V = np.zeros_like(V)\n",
        "            grad_user_bias = np.zeros_like(user_bias)\n",
        "            grad_item_bias = np.zeros_like(item_bias)\n",
        "\n",
        "            for user, movie, rating in batch:\n",
        "                pred = predict(U, V, user_bias, item_bias, global_mean, user, movie)\n",
        "                err = rating - pred\n",
        "                total_loss += err ** 2\n",
        "\n",
        "                grad_U[user] += -(err * V[movie]) + reg * U[user]\n",
        "                grad_V[movie] += -(err * U[user]) + reg * V[movie]\n",
        "                grad_user_bias[user] += -err + reg * user_bias[user]\n",
        "                grad_item_bias[movie] += -err + reg * item_bias[movie]\n",
        "\n",
        "            # Average gradients\n",
        "            grad_U /= batch_size\n",
        "            grad_V /= batch_size\n",
        "            grad_user_bias /= batch_size\n",
        "            grad_item_bias /= batch_size\n",
        "\n",
        "            # Update with momentum\n",
        "            vel_U = momentum * vel_U - lr * grad_U\n",
        "            vel_V = momentum * vel_V - lr * grad_V\n",
        "            vel_user_bias = momentum * vel_user_bias - lr * grad_user_bias\n",
        "            vel_item_bias = momentum * vel_item_bias - lr * grad_item_bias\n",
        "\n",
        "            U += vel_U\n",
        "            V += vel_V\n",
        "            user_bias += vel_user_bias\n",
        "            item_bias += vel_item_bias\n",
        "\n",
        "        mse = total_loss / len(train_data)\n",
        "        print(f\"Epoch {ep+1}/{epochs} - Train MSE: {mse:.4f}\")\n",
        "\n",
        "    return U, V, user_bias, item_bias, global_mean\n",
        "\n",
        "U, V, user_bias, item_bias, global_mean = init_model(n_users, n_movies, n_factors=75)\n",
        "\n",
        "U, V, user_bias, item_bias, global_mean = train_model_sgd_batch_momentum(\n",
        "    U, V, user_bias, item_bias, global_mean,\n",
        "    train_data,\n",
        "    n_factors=75, lr=0.01, reg=0.1,\n",
        "    epochs=75, batch_size=16, momentum=0.9\n",
        ")\n",
        "\n",
        "predictions = []\n",
        "truths = []\n",
        "\n",
        "for user, movie, real_rating in test_data:\n",
        "    pred_rating = predict(U, V, user_bias, item_bias, global_mean, user, movie)\n",
        "    predictions.append(pred_rating)\n",
        "    truths.append(real_rating)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(truths, predictions))\n",
        "print(f\"\\n✅ Test RMSE (KMSGD): {rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axth27HwDTpV",
        "outputId": "85e99201-e888-46d7-b4e5-ec6f90d665cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded! 100000 ratings: 80000 train, 20000 test.\n",
            "Epoch 1/75 - Train MSE: 1.0887\n",
            "Epoch 2/75 - Train MSE: 0.9466\n",
            "Epoch 3/75 - Train MSE: 0.8993\n",
            "Epoch 4/75 - Train MSE: 0.8730\n",
            "Epoch 5/75 - Train MSE: 0.8559\n",
            "Epoch 6/75 - Train MSE: 0.8433\n",
            "Epoch 7/75 - Train MSE: 0.8337\n",
            "Epoch 8/75 - Train MSE: 0.8258\n",
            "Epoch 9/75 - Train MSE: 0.8188\n",
            "Epoch 10/75 - Train MSE: 0.8128\n",
            "Epoch 11/75 - Train MSE: 0.8069\n",
            "Epoch 12/75 - Train MSE: 0.8018\n",
            "Epoch 13/75 - Train MSE: 0.7960\n",
            "Epoch 14/75 - Train MSE: 0.7909\n",
            "Epoch 15/75 - Train MSE: 0.7851\n",
            "Epoch 16/75 - Train MSE: 0.7794\n",
            "Epoch 17/75 - Train MSE: 0.7735\n",
            "Epoch 18/75 - Train MSE: 0.7670\n",
            "Epoch 19/75 - Train MSE: 0.7607\n",
            "Epoch 20/75 - Train MSE: 0.7539\n",
            "Epoch 21/75 - Train MSE: 0.7470\n",
            "Epoch 22/75 - Train MSE: 0.7400\n",
            "Epoch 23/75 - Train MSE: 0.7325\n",
            "Epoch 24/75 - Train MSE: 0.7255\n",
            "Epoch 25/75 - Train MSE: 0.7184\n",
            "Epoch 26/75 - Train MSE: 0.7111\n",
            "Epoch 27/75 - Train MSE: 0.7040\n",
            "Epoch 28/75 - Train MSE: 0.6967\n",
            "Epoch 29/75 - Train MSE: 0.6897\n",
            "Epoch 30/75 - Train MSE: 0.6826\n",
            "Epoch 31/75 - Train MSE: 0.6759\n",
            "Epoch 32/75 - Train MSE: 0.6691\n",
            "Epoch 33/75 - Train MSE: 0.6622\n",
            "Epoch 34/75 - Train MSE: 0.6553\n",
            "Epoch 35/75 - Train MSE: 0.6488\n",
            "Epoch 36/75 - Train MSE: 0.6423\n",
            "Epoch 37/75 - Train MSE: 0.6356\n",
            "Epoch 38/75 - Train MSE: 0.6294\n",
            "Epoch 39/75 - Train MSE: 0.6230\n",
            "Epoch 40/75 - Train MSE: 0.6169\n",
            "Epoch 41/75 - Train MSE: 0.6107\n",
            "Epoch 42/75 - Train MSE: 0.6048\n",
            "Epoch 43/75 - Train MSE: 0.5990\n",
            "Epoch 44/75 - Train MSE: 0.5930\n",
            "Epoch 45/75 - Train MSE: 0.5875\n",
            "Epoch 46/75 - Train MSE: 0.5821\n",
            "Epoch 47/75 - Train MSE: 0.5765\n",
            "Epoch 48/75 - Train MSE: 0.5714\n",
            "Epoch 49/75 - Train MSE: 0.5663\n",
            "Epoch 50/75 - Train MSE: 0.5614\n",
            "Epoch 51/75 - Train MSE: 0.5562\n",
            "Epoch 52/75 - Train MSE: 0.5519\n",
            "Epoch 53/75 - Train MSE: 0.5470\n",
            "Epoch 54/75 - Train MSE: 0.5426\n",
            "Epoch 55/75 - Train MSE: 0.5383\n",
            "Epoch 56/75 - Train MSE: 0.5341\n",
            "Epoch 57/75 - Train MSE: 0.5302\n",
            "Epoch 58/75 - Train MSE: 0.5259\n",
            "Epoch 59/75 - Train MSE: 0.5223\n",
            "Epoch 60/75 - Train MSE: 0.5183\n",
            "Epoch 61/75 - Train MSE: 0.5148\n",
            "Epoch 62/75 - Train MSE: 0.5115\n",
            "Epoch 63/75 - Train MSE: 0.5079\n",
            "Epoch 64/75 - Train MSE: 0.5049\n",
            "Epoch 65/75 - Train MSE: 0.5014\n",
            "Epoch 66/75 - Train MSE: 0.4983\n",
            "Epoch 67/75 - Train MSE: 0.4952\n",
            "Epoch 68/75 - Train MSE: 0.4924\n",
            "Epoch 69/75 - Train MSE: 0.4899\n",
            "Epoch 70/75 - Train MSE: 0.4870\n",
            "Epoch 71/75 - Train MSE: 0.4843\n",
            "Epoch 72/75 - Train MSE: 0.4816\n",
            "Epoch 73/75 - Train MSE: 0.4791\n",
            "Epoch 74/75 - Train MSE: 0.4769\n",
            "Epoch 75/75 - Train MSE: 0.4743\n",
            "\n",
            "✅ Test RMSE (KMSGD): 0.9086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sliding wall SGD"
      ],
      "metadata": {
        "id": "X4xuiLrnasu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load and prepare data\n",
        "ratings_df = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "ratings_df['user_id'] -= 1\n",
        "ratings_df['movie_id'] -= 1\n",
        "\n",
        "ratings_list = list(ratings_df[['user_id', 'movie_id', 'rating']].itertuples(index=False, name=None))\n",
        "n_users = ratings_df['user_id'].nunique()\n",
        "n_movies = ratings_df['movie_id'].nunique()\n",
        "\n",
        "train_data, test_data = train_test_split(ratings_list, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Data Loaded! {len(ratings_list)} ratings: {len(train_data)} train, {len(test_data)} test.\")\n",
        "\n",
        "def init_model(n_users, n_movies, n_factors=20):\n",
        "    np.random.seed(0)\n",
        "    U = np.random.normal(0, 0.1, (n_users, n_factors))\n",
        "    V = np.random.normal(0, 0.1, (n_movies, n_factors))\n",
        "    return U, V\n",
        "\n",
        "def train_swsgd(U, V, train_data, n_factors=20, lr=0.01, reg=0.1, epochs=30, wall_size=1000, sample_k=5):\n",
        "    wall = []  # Sliding wall buffer\n",
        "    total_ratings = len(train_data)\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        np.random.shuffle(train_data)\n",
        "        total_loss = 0\n",
        "        count = 0\n",
        "\n",
        "        for user, movie, rating in train_data:\n",
        "            # Add to wall\n",
        "            wall.append((user, movie, rating))\n",
        "            if len(wall) > wall_size:\n",
        "                wall.pop(0)  # Maintain sliding window\n",
        "\n",
        "            # Sample from wall\n",
        "            sample_size = min(sample_k, len(wall))\n",
        "            sample_indices = np.random.choice(len(wall), size=sample_size, replace=False)\n",
        "\n",
        "            for idx in sample_indices:\n",
        "                u, i, r_ui = wall[idx]\n",
        "                pred = np.dot(U[u], V[i])\n",
        "                err = r_ui - pred\n",
        "\n",
        "                total_loss += err ** 2\n",
        "                count += 1\n",
        "\n",
        "                # SGD update\n",
        "                U[u] += lr * (err * V[i] - reg * U[u])\n",
        "                V[i] += lr * (err * U[u] - reg * V[i])\n",
        "\n",
        "        mse = total_loss / count\n",
        "        print(f\"Epoch {ep+1}/{epochs} - Train MSE: {mse:.4f}\")\n",
        "\n",
        "    return U, V\n",
        "\n",
        "# Initialize and train\n",
        "U, V = init_model(n_users, n_movies, n_factors=50)\n",
        "U, V = train_swsgd(U, V, train_data, n_factors=50, lr=0.01, reg=0.1, epochs=75, wall_size=1000, sample_k=5)\n",
        "\n",
        "# Evaluate\n",
        "predictions = []\n",
        "truths = []\n",
        "\n",
        "for user, movie, real_rating in test_data:\n",
        "    pred_rating = np.dot(U[user], V[movie])\n",
        "    predictions.append(pred_rating)\n",
        "    truths.append(real_rating)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(truths, predictions))\n",
        "print(f\"\\n✅ Test RMSE (Sliding Wall SGD): {rmse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do-Ns3mYHUL_",
        "outputId": "451fa8e6-b07c-4311-e6df-c386983b079b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded! 100000 ratings: 80000 train, 20000 test.\n",
            "Epoch 1/75 - Train MSE: 3.0429\n",
            "Epoch 2/75 - Train MSE: 0.6742\n",
            "Epoch 3/75 - Train MSE: 0.6141\n",
            "Epoch 4/75 - Train MSE: 0.5749\n",
            "Epoch 5/75 - Train MSE: 0.5447\n",
            "Epoch 6/75 - Train MSE: 0.5176\n",
            "Epoch 7/75 - Train MSE: 0.4975\n",
            "Epoch 8/75 - Train MSE: 0.4805\n",
            "Epoch 9/75 - Train MSE: 0.4665\n",
            "Epoch 10/75 - Train MSE: 0.4546\n",
            "Epoch 11/75 - Train MSE: 0.4467\n",
            "Epoch 12/75 - Train MSE: 0.4383\n",
            "Epoch 13/75 - Train MSE: 0.4316\n",
            "Epoch 14/75 - Train MSE: 0.4262\n",
            "Epoch 15/75 - Train MSE: 0.4200\n",
            "Epoch 16/75 - Train MSE: 0.4165\n",
            "Epoch 17/75 - Train MSE: 0.4127\n",
            "Epoch 18/75 - Train MSE: 0.4076\n",
            "Epoch 19/75 - Train MSE: 0.4061\n",
            "Epoch 20/75 - Train MSE: 0.4030\n",
            "Epoch 21/75 - Train MSE: 0.4025\n",
            "Epoch 22/75 - Train MSE: 0.4004\n",
            "Epoch 23/75 - Train MSE: 0.3965\n",
            "Epoch 24/75 - Train MSE: 0.3968\n",
            "Epoch 25/75 - Train MSE: 0.3955\n",
            "Epoch 26/75 - Train MSE: 0.3931\n",
            "Epoch 27/75 - Train MSE: 0.3908\n",
            "Epoch 28/75 - Train MSE: 0.3937\n",
            "Epoch 29/75 - Train MSE: 0.3918\n",
            "Epoch 30/75 - Train MSE: 0.3896\n",
            "Epoch 31/75 - Train MSE: 0.3896\n",
            "Epoch 32/75 - Train MSE: 0.3904\n",
            "Epoch 33/75 - Train MSE: 0.3874\n",
            "Epoch 34/75 - Train MSE: 0.3879\n",
            "Epoch 35/75 - Train MSE: 0.3878\n",
            "Epoch 36/75 - Train MSE: 0.3868\n",
            "Epoch 37/75 - Train MSE: 0.3836\n",
            "Epoch 38/75 - Train MSE: 0.3846\n",
            "Epoch 39/75 - Train MSE: 0.3852\n",
            "Epoch 40/75 - Train MSE: 0.3842\n",
            "Epoch 41/75 - Train MSE: 0.3837\n",
            "Epoch 42/75 - Train MSE: 0.3821\n",
            "Epoch 43/75 - Train MSE: 0.3832\n",
            "Epoch 44/75 - Train MSE: 0.3814\n",
            "Epoch 45/75 - Train MSE: 0.3811\n",
            "Epoch 46/75 - Train MSE: 0.3815\n",
            "Epoch 47/75 - Train MSE: 0.3829\n",
            "Epoch 48/75 - Train MSE: 0.3824\n",
            "Epoch 49/75 - Train MSE: 0.3794\n",
            "Epoch 50/75 - Train MSE: 0.3819\n",
            "Epoch 51/75 - Train MSE: 0.3803\n",
            "Epoch 52/75 - Train MSE: 0.3784\n",
            "Epoch 53/75 - Train MSE: 0.3794\n",
            "Epoch 54/75 - Train MSE: 0.3798\n",
            "Epoch 55/75 - Train MSE: 0.3787\n",
            "Epoch 56/75 - Train MSE: 0.3793\n",
            "Epoch 57/75 - Train MSE: 0.3782\n",
            "Epoch 58/75 - Train MSE: 0.3781\n",
            "Epoch 59/75 - Train MSE: 0.3782\n",
            "Epoch 60/75 - Train MSE: 0.3778\n",
            "Epoch 61/75 - Train MSE: 0.3781\n",
            "Epoch 62/75 - Train MSE: 0.3799\n",
            "Epoch 63/75 - Train MSE: 0.3782\n",
            "Epoch 64/75 - Train MSE: 0.3781\n",
            "Epoch 65/75 - Train MSE: 0.3777\n",
            "Epoch 66/75 - Train MSE: 0.3774\n",
            "Epoch 67/75 - Train MSE: 0.3760\n",
            "Epoch 68/75 - Train MSE: 0.3781\n",
            "Epoch 69/75 - Train MSE: 0.3783\n",
            "Epoch 70/75 - Train MSE: 0.3764\n",
            "Epoch 71/75 - Train MSE: 0.3767\n",
            "Epoch 72/75 - Train MSE: 0.3774\n",
            "Epoch 73/75 - Train MSE: 0.3761\n",
            "Epoch 74/75 - Train MSE: 0.3774\n",
            "Epoch 75/75 - Train MSE: 0.3756\n",
            "\n",
            "✅ Test RMSE (Sliding Wall SGD): 0.9593\n"
          ]
        }
      ]
    }
  ]
}